{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058a7511-2ea4-4a51-97c5-ce3abe87c934",
   "metadata": {},
   "source": [
    "Step 1: Install spaCy and Download Language Model\n",
    "First, make sure you have spaCy installed and download a language model. For example, you can download the English language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57eb2b-7602-4291-9761-b43bcba5c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548c502-129e-4924-b37d-319b4e8455c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 2: Data Loading and Cleaning\n",
    "Assume you have a dataset stored in a CSV file. Here's how you can load and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511bab7-4b40-4000-ac0e-9379e59a174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example dataset (replace with your own dataset)\n",
    "data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"Apple is looking at buying U.K. startup for $1 billion.\",\n",
    "        \"I love reading books in the library.\",\n",
    "        \"John Doe lives in New York City.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Function for text cleaning and spaCy processing\n",
    "def process_text(text):\n",
    "    # Remove extra whitespace\n",
    "    text = text.strip()\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    return doc\n",
    "\n",
    "# Apply processing function to the 'text' column\n",
    "data['processed'] = data['text'].apply(process_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f411c3-fb0c-46a3-b7dd-b3ce39273ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a86e9a-4870-4df9-af94-4b381da64331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Named Entity Recognition (NER) analysis\n",
    "entities = []\n",
    "for doc in data['processed']:\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "\n",
    "# Convert entities to DataFrame\n",
    "entities_df = pd.DataFrame(entities, columns=['Entity', 'Label'])\n",
    "\n",
    "# Count and plot entity labels\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(y='Label', data=entities_df, palette='viridis')\n",
    "plt.title('Named Entity Recognition (NER)')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Entity Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e49a4-4224-4b03-8bbb-a30b2e272fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 4: Visualization\n",
    "Visualize token frequencies or any other relevant insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd343da-1fbe-48ce-8c03-9312c72afa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Token frequency visualization\n",
    "from collections import Counter\n",
    "\n",
    "all_tokens = []\n",
    "for doc in data['processed']:\n",
    "    tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# Count token frequencies\n",
    "token_freq = Counter(all_tokens)\n",
    "\n",
    "# Plot top 20 tokens\n",
    "top_tokens = token_freq.most_common(20)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[token[1] for token in top_tokens], y=[token[0] for token in top_tokens], palette='muted')\n",
    "plt.title('Top 20 Most Common Tokens')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Token')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5316a7-e5a4-41a2-a03b-ac5bda1324b4",
   "metadata": {},
   "source": [
    "Additional Steps (Optional)\n",
    "You can extend this example with more advanced spaCy features such as dependency parsing, sentiment analysis, or customizing the processing pipeline based on your specific needs.\n",
    "\n",
    "Conclusion\n",
    "This implementation demonstrates how to perform basic data analysis on an NLP dataset using spaCy in Python. SpaCy provides powerful capabilities for text processing, entity recognition, and syntactic analysis, making it suitable for a wide range of NLP tasks. Depending on your dataset and objectives, you can further customize and expand upon these examples to extract meaningful insights from your text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2cabb-e37f-48d2-a700-a2e79feeb289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
