{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision (S1-24_AIMLCZG525) - Assignment 1\n",
    "#### CV Group 19 \n",
    "    SAYANTA CHATTERJEE - 2023aa05173\n",
    "\n",
    "    TAIBA REHMAN - 2023aa05466\n",
    "\n",
    "    KASHYAP RAJPUROHIT - 2023ab05027\n",
    "\n",
    "    C RAMAKRISHNA - 2023ab05177\n",
    "\n",
    "### Problem Statement 2: \"Edge-based Image Retrieval\"\n",
    "\n",
    "#### Objective: Implement an image retrieval system that uses edge-based features to find similar images in a dataset. Evaluate the retrieval performance using relevant metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.Import the required libraries\n",
    "\n",
    "Import the necessary libraries for image processing (e.g., OpenCV, scikit-image) and machine learning (e.g., scikit-learn, pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import  accuracy_score, precision_score, recall_score, f1_score, average_precision_score, pairwise_distances\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Data Acquisition\n",
    "\n",
    "•\tDownload the Caltech 101 dataset from the provided link: Caltech 101 DatasetLinks to an external site.\n",
    "\n",
    "•\tSelect any 5 categories from the dataset. Each category should have at least 50 images.\n",
    "\n",
    "•\tOrganize the selected categories into separate folders, with each folder containing the corresponding images.\n",
    "\n",
    "•\tAnalyze and plot the distribution of images per category using a bar graph or pie chart.\n",
    "\n",
    "Url for the dataset: \n",
    "https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip?download=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/asus/OneDrive/Desktop/CVassimgement/caltech-101/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m folder_contents \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path)\n\u001b[0;32m      3\u001b[0m folder_names \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m folder_contents \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, name))]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Select categories with at least 50 images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = r\"C:/Users/asus/OneDrive/Desktop/CVassimgement/caltech-101/\"\n",
    "folder_contents = os.listdir(folder_path)\n",
    "folder_names = [name for name in folder_contents if os.path.isdir(os.path.join(folder_path, name))]\n",
    "\n",
    "# Select categories with at least 50 images\n",
    "randomsa = []\n",
    "for folder_name in folder_names:\n",
    "    folder_contents = os.listdir(os.path.join(folder_path, folder_name))\n",
    "    if len(folder_contents) >= 50:\n",
    "        randomsa.append(folder_name)\n",
    "\n",
    "# Select 5 random categories\n",
    "selected_folders = random.sample(randomsa, 5)\n",
    "\n",
    "# Create a new directory to organize the selected categories\n",
    "organized_folder_path = r\"C:/Users/asus/OneDrive/Desktop/CVassimgement/organized_caltech101/\"\n",
    "os.makedirs(organized_folder_path, exist_ok=True)\n",
    "\n",
    "# Organize the selected categories into separate folders\n",
    "for folder_name in selected_folders:\n",
    "    src_folder = os.path.join(folder_path, folder_name)\n",
    "    dest_folder = os.path.join(organized_folder_path, folder_name)\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, file_name)\n",
    "        dest_file = os.path.join(dest_folder, file_name)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Analyze and plot the distribution of images per category\n",
    "category_counts = {folder_name: len(os.listdir(os.path.join(organized_folder_path, folder_name))) for folder_name in selected_folders}\n",
    "print(category_counts)\n",
    "# Plotting the distribution using a bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_counts.keys(), category_counts.values(), color='skyblue')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Images per Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the distribution using a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(category_counts.values(), labels=category_counts.keys(), autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Images per Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.  Data Preparation\n",
    "\n",
    "Randomly split the dataset into training and testing sets using an 80% training and 20% testing ratio. Ensure that the split is stratified, maintaining the same proportion of images per category in both sets.\n",
    "\n",
    "**Note:** This step is integrated in the **Task 5** in the code below.\n",
    "\n",
    "\n",
    "### Task 4: **Preprocess** the images as follows:\n",
    "\n",
    "•\tConvert the images to grayscale.\n",
    "\n",
    "•\tApply the Canny edge detection algorithm to extract edges from the images.\n",
    "\n",
    "•\tExtract edge-based descriptors such as edge histograms or gradient histograms from the preprocessed images.\n",
    "\n",
    "•\tCreate multiple feature sets by varying the parameters of the edge detection and descriptor extraction methods.\n",
    "\n",
    "•\tStore the extracted features in separate dataframes, along with the corresponding category labels.\n",
    "\n",
    "•\tNormalize the feature values using techniques like min-max scaling or z-score normalization.\n",
    "\n",
    "•\tIf the feature dimensionality is too high, apply dimensionality reduction techniques such as PCA or resize the images to a smaller fixed size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(image):\n",
    "    # Display the edge-detected image\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Edge Detection\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPreProcess(image_path, canny_low, canny_high):\n",
    "    if(os.path.exists(image_path)):\n",
    "        # Load the image as gray scale\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE )\n",
    "        # resize the image for uniform feature length\n",
    "        resized = cv2.resize(image, (256,128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Apply Gaussian Blur\n",
    "        blurred = cv2.GaussianBlur(resized, (5, 5), 0)\n",
    "        # Apply Canny for edge detection\n",
    "        return cv2.Canny(blurred, canny_low, canny_high)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHOGFeatures(image, cellSize, blockSize, blockStride):\n",
    "    winSize = (256,128) # scaled image size\n",
    "    nbins = 9\n",
    "\n",
    "    # HOG from preprocessed image\n",
    "    hog = cv2.HOGDescriptor(_winSize = winSize, _cellSize = cellSize, _blockSize = blockSize, _nbins= nbins, _blockStride = blockStride)\n",
    "    return hog.compute(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(base_path, folder_names, params):\n",
    "    features = list()\n",
    "    category = list()\n",
    "    image_names = list()\n",
    "    for folder_name in folder_names:\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        # get and extract feature from all files in current folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            image = loadPreProcess(os.path.join(folder_path, file_name), params['canny_low'], params['canny_high'])\n",
    "            features.append(getHOGFeatures(image, params['cell_size'], params['block_size'], params['block_stride']))\n",
    "            category.append(folder_name)\n",
    "            image_names.append(file_name)\n",
    "\n",
    "    # z-score normalization feature set\n",
    "    scaler = StandardScaler()\n",
    "    norm_data = scaler.fit_transform(features)\n",
    "\n",
    "    # PCA to reduce dimentionality\n",
    "    pca = PCA(n_components=0.98)\n",
    "    pca_data = pca.fit_transform(norm_data)\n",
    "\n",
    "    data = pd.DataFrame(pca_data)\n",
    "    data['category'] = category\n",
    "    data['image_name'] = image_names\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Model Building\n",
    "\n",
    "* Select a classical machine learning algorithm such as Support Vector Machines (SVM), Random Forest, or XGBoost for training the image retrieval model.\n",
    "\n",
    "* Train the chosen model on different feature combinations created in the preprocessing step.\n",
    "\n",
    "* Use appropriate hyperparameter tuning techniques (e.g., grid search, random search) and cross-validation (e.g., k-fold) to optimize the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y):\n",
    "    # define model\n",
    "    model = SVC()\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "    }\n",
    "\n",
    "    # k-fold with grid search cross validation\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    \n",
    "    print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Validation Metrics\n",
    "\n",
    "Evaluate the trained models using the following metrics:\n",
    "\n",
    "    o\tAccuracy\n",
    "    o\tPrecision\n",
    "    o\tRecall\n",
    "    o\tF1 score\n",
    "    o\tMean Average Precision (mAP)\n",
    "\n",
    "Calculate the mAP by ranking the retrieved images based on their similarity scores and computing the average precision at different recall levels.\n",
    "Aim for a minimum mAP of 0.7 to consider the retrieval system as acceptable.\n",
    "\n",
    "Note: The accuracy is siplay in the output of the above cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    car_side       1.00      0.96      0.98        25\n",
      " cougar_face       0.75      0.64      0.69        14\n",
      "   crocodile       0.54      0.70      0.61        10\n",
      "         cup       0.82      0.82      0.82        11\n",
      "   dragonfly       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.82        74\n",
      "   macro avg       0.79      0.80      0.79        74\n",
      "weighted avg       0.84      0.82      0.83        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calcultate_map(test_y,pred_y):\n",
    "    binarized_test_y = label_binarize(test_y, classes=np.unique(test_y))\n",
    "    binarized_pred_y = label_binarize(pred_y, classes=np.unique(test_y))\n",
    "    ap_scores = []\n",
    "    for i in range(binarized_test_y.shape[1]):\n",
    "        ap = average_precision_score(binarized_test_y[:, i], binarized_pred_y[:, i])\n",
    "        ap_scores.append(ap)\n",
    "    \n",
    "    map_score = np.mean(ap_scores)\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_x, test_y):\n",
    "    pred_y = model.predict(test_x)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_y, pred_y)\n",
    "    precision = precision_score(test_y, pred_y, average='weighted')\n",
    "    recall = recall_score(test_y, pred_y, average='weighted')\n",
    "    f1 = f1_score(test_y, pred_y, average='weighted')\n",
    "    map_score = calcultate_map(test_y, pred_y)\n",
    "\n",
    "    # 8. Analysis and Discussion\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"MAP: {map_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The mean average precision (mAP) is calculated above with a value as **0.68**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7. Model Inference \n",
    "\n",
    "•\tRandomly select 5 test images from each category and use the best-performing model to retrieve the top-5 most similar images for each query image.\n",
    "\n",
    "•\tDisplay the query image along with its top-5 retrieved images, their predicted labels, and the actual labels.\n",
    "\n",
    "•\tJustify your choice of features based on the retrieval performance and visual analysis of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cv2.HOGDescriptor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_BasePCA.transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_image_path \u001b[38;5;129;01min\u001b[39;00m query_images:\n\u001b[0;32m     27\u001b[0m     query_image \u001b[38;5;241m=\u001b[39m loadPreProcess(query_image_path)\n\u001b[1;32m---> 28\u001b[0m     top_k_images, top_k_labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_k_similar_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Display query image and top-5 retrieved images\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[22], line 11\u001b[0m, in \u001b[0;36mget_top_k_similar_images\u001b[1;34m(query_image, k)\u001b[0m\n\u001b[0;32m      9\u001b[0m query_features \u001b[38;5;241m=\u001b[39m getFeatures(query_image)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m query_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(query_features)\n\u001b[1;32m---> 11\u001b[0m query_features \u001b[38;5;241m=\u001b[39m \u001b[43mPCA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m distances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecision_function(query_features)\n\u001b[0;32m     13\u001b[0m top_k_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m-\u001b[39mk:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: _BasePCA.transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "def get_top_k_similar_images(model, source, image_data, k=5):\n",
    "    pred_cat = model.predict(image_data)\n",
    "    distances = pairwise_distances(source, image_data, metric='cosine').ravel()\n",
    "    top_k_indices = np.argsort(distances)[:-k]\n",
    "    return pred_cat, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params_1  ={\n",
    "    'canny_low': 50,\n",
    "    'canny_high': 150,\n",
    "    'cell_size' : (16,16), # in pixel\n",
    "    'block_size' : (32,32), # multiple of cell size\n",
    "    'block_stride':(16,16) # multiple of cell size\n",
    "}\n",
    "\n",
    "data_1 = loadData(organized_folder_path, category_counts.keys(), feature_params_1)\n",
    "vector_1 =data_1.iloc[:, :-2]\n",
    "category = data_1.iloc[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(vector_1, category, train_size=0.8, stratify=category )\n",
    "model = train(train_x, train_y)\n",
    "test(model, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 5 test images from each selected folder\n",
    "for folder in selected_folders:\n",
    "    folder_dir = os.path.join(organized_folder_path, folder)\n",
    "    file_name = random.sample(os.listdir(folder_dir), 1)[0]\n",
    "    image_data = data_1.query(f\"category ==  '{folder}' & image_name == '{file_name}'\").iloc[:,:-2]\n",
    "    pred_label, top_k_match = get_top_k_similar_images(model, vector_1, image_data)\n",
    "\n",
    "    # Display query image and top-5 retrieved images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(cv2.imread(os.path.join(folder_dir, file_name)), cmap='gray')\n",
    "    plt.title(pred_label)\n",
    "    plt.axis('off')\n",
    "    \n",
    "      \n",
    "    for i in range(5):\n",
    "        category = data_1.iloc[top_k_match[i]]['category']\n",
    "        file_name = data_1.iloc[top_k_match[i]]['image_name']\n",
    "        img = cv2.imread(os.path.join(organized_folder_path, category, file_name))\n",
    "        plt.subplot(1, 6, i + 2)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Top-{i+1}: {category}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8356164383561644\n",
      "Precision: 0.8608393128941075\n",
      "Recall: 0.8356164383561644\n",
      "F1-score: 0.8349502723569266\n",
      "mAP: 0.74053909352056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_y, pred_y)\n",
    "precision = precision_score(test_y, pred_y, average='weighted')\n",
    "recall = recall_score(test_y, pred_y, average='weighted')\n",
    "f1 = f1_score(test_y, pred_y, average='weighted')\n",
    "\n",
    "# 8. Analysis and Discussion\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"mAP: {map_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8.  Analysis and Discussion\n",
    "\n",
    "•\tAnalyze the retrieval results and discuss the effectiveness of the edge-based features for image retrieval.\n",
    "\n",
    "•\tCompare the performance of different feature combinations and highlight the ones that yield the best results.\n",
    "\n",
    "•\tIdentify any limitations or challenges encountered during the implementation and suggest potential improvements or alternative approaches.\n",
    "        1. Resizing of the images due to different size \n",
    "\n",
    "        2. CNN for better accuracy\n",
    "    \n",
    "        3. Canny edge detection limitation\n",
    "    \n",
    "        4. HOG limitation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
